# Acoustic distance measure application

This repository implements an evaluation pipeline for comparing neural acoustic representations of audio pronunciations using dynamic time warping (DTW), following the paper [Neural representations for modeling variation in speech](https://www.sciencedirect.com/science/article/pii/S0095447022000122#s0100). The pipeline includes:
- Downloading and preparing the dataset,
- Resampling audio files to a standardized format,
- Extracting features using pre-trained wav2vec 2.0 models,
- Computing DTW distances between feature representations.


## Directory structure

```bash
audio-eval/
├── cache/                               # Cached Hugging Face files and models
├── datasets/                            # Contains downloaded dataset (wiktionary_pronunciations-final)
│   └── wiktionary_pronunciations-final/
│       ├── audios/
│       │   ├── wiktionary/              # Original audio files from Wiktionary
│       │   └── GPT4o/                   # Audio files generated by GPT4o
│       └── ...                          # Other dataset files
├── feats/                               # Extracted features (organized per model and speaker)
├── output/                              # Final outputs (CSV with DTW distances)
└── scripts/
    ├── download_data.py                 # Downloads dataset and saves audio files locally
    ├── resample.sh                      # Resamples WAV files to 16kHz, mono, 16-bit using sox
    └── acoustic_distance/
        ├── extract_features.py          # Extracts features using a chosen wav2vec 2.0 model and layer
        ├── acoustic_distance.py         # Computes DTW distances between feature sets
```

## Requirements

- Python 3.7+

```bash
pip install -r scripts/acoustic_distance/requirements.txt
```

## Pipeline overview

1. **Download and prepare data**

- The `download_data.py` script downloads the dataset *wiktionary_pronunciations-final* from Hugging Face (dataset: `MichaelR207/wiktionary_pronunciations-final`).
- Audio files are extracted and stored in two subdirectories:
    - `audios/wiktionary`
    - `audios/GPT4o`
- Files are saved as wav files with the naming format: `<index>_<OED>.wav`.

Run the script:
```bash
cd scripts
python download_data.py
```

## 2. Resample audio files
The `resample.sh` script re-encodes wav files using `sox`. It converts files to a 16 kHz sampling rate, mono channel, and 16-bit PCM.
Run the script:
```bash
bash resample.sh
```

## 3. Feature extraction
The `extract_features.py` script extracts acoustic features using the wav2vec 2.0 model and layer that performed best in the paper [Neural representations for modeling variation in speech](https://www.sciencedirect.com/science/article/pii/S0095447022000122#s0100). You can specify the model (e.g., wav2vec2-large-960h) and the layer (e.g., 10) to extract features. Features are computed for each wav file in the input directory and saved as NumPy arrays.

Run the feature extraction commands:
```bash
cd acoustic_distance

# For GPT4o-generated audio
python extract_features.py -m wav2vec2-large-960h -l 10 -i ../../datasets/wiktionary_pronunciations-final/audios/GPT4o -o ../../feats/wiktionary_pronunciations-final/GPT4o/{model}/{speaker}

# For Wiktionary audio
python extract_features.py -m wav2vec2-large-960h -l 10 -i ../../datasets/wiktionary_pronunciations-final/audios/wiktionary -o ../../feats/wiktionary_pronunciations-final/wiktionary/{model}/{speaker}
```

## 4. Compute DTW distances
The `acoustic_distance.py` script computes the Dynamic Time Warping (DTW) distance between the corresponding feature representations from the GPT4o and Wiktionary datasets. It saves the final results, including the instance ID, labels, and normalized DTW distance, to a csv file.

Run the script:
```bash
python acoustic_distance.py
```

## Final output
The computed DTW distances are saved in the `output/` directory.

For example, when using layer 10, the output file is:
```
../output/dtw_distances_layer-10.csv
```

A sample of the CSV output:
```
instance_id,label_gpt4o,label_wiktionary,dtw_distance
0,pur-SENT,pur-SENT,10.0803
1,wun·-oh·-WUN,wun·-oh·-WUN,10.1151
...
13139,meti·-KAHL,meti·-KAHL,14.209
...
```

Each row in the CSV contains:
- `instance_id`: A unique identifier for the word/pronunciation.
- `label_gpt4o`: The label associated with the GPT4o pronunciation.
- `label_wiktionary`: The label from the Wiktionary audio.
- `dtw_distance`: The normalized DTW distance between the feature representations.

## References
For more details on the method, refer to the paper [Neural representations for modeling variation in speech](https://www.sciencedirect.com/science/article/pii/S0095447022000122#s0100).
